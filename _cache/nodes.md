# Cache的需求

- 需要较高读写性能+命中率
- 支持按写入时间过期
- 支持淘汰策略
- 需要解决gc，大量stw扫描，cpu

![image-20220424221258614](./img/image-20220424221258614.png)



## FastCache

特点:

- 线程安全(多个桶，降低并发冲突)
- 存储大量的cache实体，而且不会被GC扫描（堆内存unix.Mmap）
  - 内存映射的方式可以直接向操作系统申请内存，这块区域不归GC管。所以不管你在这块内存缓存了多少数据，都不会因为GC扫描而影响性能。
  - 但是这里分配的内存再也不会被释放，直到进程重启

- cache空间满了以后，fastcache会自动淘汰老数据块（RingBuf）
- 内存不会预先分配，随用随分配



fastcache为什么快，因为用了这些手段：

1. 使用mmap来成块的分配内存。
   - 每次直接向操作系统要64MB，这些内存都绕开了GC。
   - 每次以64KB为单位请求一个块
   - 在64KB的块内顺序存储，相当于更简单的自己实现的分配算法
2. 整个cache分成512个bucket
   - 相当于有了512个map+512个读写锁，通过这样减少了竞争
   - map类型的key和value都是整形，容量小，且对GC友好
   - 淘汰用轮换的方法+固定次数的set后再清理，解决了（或者说绕开了）碎片的问题

优点

- 快速地。多核 CPU 上的性能可扩展。请参阅下面的基准测试结果。
- 线程安全。并发 goroutine 可以读取和写入单个缓存实例。
- fastcache 设计用于在没有GC 开销的情况下存储大量条目 。
- 当达到创建时设置的最大缓存大小时，Fastcache 会自动驱逐旧条目。
- 简单的 API。
- 简单的源代码。
- 缓存可以保存到文件 并从文件加载。







## BigCache

### 是什么？

今天我们来一起学习下BigCache，BigCache是一个go开源的缓存库。

首先这个库有那些优点：

- 存储百万的缓存条目也要非常快。
- 支持大并发访问。
- 支持在一定时间后剔除缓存条目。
- 几乎 0 GC

### 怎么用？

1.设置和获取

2.hash冲突

3.过期删除

4.定时删除

5.删除回调

### 为什么？

我来了解它的常用功能后，再来看看它是怎么设计的。

- 数据结构设计
- 核心特点
  - 为什么要分片（降低并发冲突）
  - 为什么要用map存储索引位置。（减少gc时间）
  - 为什么要用[]byte存储数据（适配map存储偏移量）





为什么要设计出bigcache（背景）？

bigcache的作者在开发项目时需要用到缓存，并有一些需求：

- cache要支持http协议访问数据。
- cache要支持 **10K** RPS (5k 写，5k 读)。
- cache对象至少保持10分钟。
- 响应时间（在没有花费在网络上的时间的情况下测量）低于。
  - 5ms – 平均值
  - 第 99.9 个百分位数为 10 毫秒
  - 第 99.999 个百分位数为 400 毫秒
- 其它.....

缓存本身需要满足的要求:

- 即使有百万的缓存对象也要非常快。
- 支持大并发访问。
- 在一定时间后剔除条目。

首先，为了满足百万的缓存对象也要非常快，需要选择一个合适的数据结构。map就是一个非常不错的的结构，可以通过O(1)的时间复杂度获取数据。示例如下：

```go

```

如上通过map存储数据，在数据量比较大并发比较高的时候会延长 GC 时间，增加访问缓存的延迟，增加内存分配次数。应为`string` 实际上底层数据结构是由两部分组成，其中包含指向字节数组的指针和数组的大小：

```go
type StringHeader struct {
    Data uintptr
    Len  int
}
```

由于 `StringHeader`中包含指针，所以每次 GC 的时候都会扫描每个指针，那么在这个巨大的 `map`中是包含了非常多的指针的，所以造成了巨大的资源消耗。

如何解决GC停顿导致的延迟：

1. 导致GC停顿的主要原因是map内保存的指针太多，导致扫描一遍需要很长时间，那可以从减少指针使用入手。（代表：Freecache）
1. 可以考虑让我们存储数据的结构直接不被扫描，那就不会有停顿了。因为垃圾回收器检查的是堆上的资源，如果不把数据放在堆上，不就解决这个问题了吗？（代表：offheap）但堆外内存很容易产生内存泄漏。
2. 可以利用Go 1.5中修复的一个issue([#9477](https://github.com/golang/go/issues/9477)), 这个issue描述了Go的开发者优化了垃圾回收时对于map的处理，如果map对象中的key和value不包含指针，那么GC 便会忽略这个 map

其次，数据都是共享的要支持并发访问就要加锁访问，当大并发访问时大量的锁冲突会降低访问效率。我们要做的是尽量避免冲突，降低并发冲突可以通过分片做到，当写入数据时可以通过hash函数和取余运算，将数据分配到不同的分片上，每个分片都有各自的读写锁，各个分片互不影响，这大大降低了并发冲突。



bigcache就是利用这些特性，首先bigcache内存结构包含一个分片数组。 每个分片有自己的存储结构(一个大循环[]bytes用来存储实际数据)，索引结构(map[uint64\]\[uint32]保存索引,key存储数据相关的hash值，value存储数据实际存储在[]bytes中的偏移量)和读写锁。



set流程





get流程





删除回调流程













缓存的实现离不开如下几种：

1. 原生 `map`
2. `sync.Map`
3. 基于以上二者封装的复合型 `map`

前两者的缺点也很明显：

1. 当 `map` 中存在大量 keys 时，GC 扫描 `map` 产生的停顿将不能忽略（针对 `map` 中存储指针或数据类型底层也是由指针实现这样的场景）
2. 加锁的粒度

提高缓存性能的手段也是明确的：

1. 减少 GC
2. `map` 中尽量避免存储指针
3. 分段（Shards）存储，减少 `lock`

具体实现：

1. 索引（index）与数据（data）分离存储的 `map` 结构
   - 这样 GC 就变成了 `map` 无指针结构 和 `[]byte` 结构的扫描问题
2. GoLang 1.5 版本的 [优化说明](https://github.com/golang/go/issues/9477): 如果 `map` 的 key 或 value 中都不含指针, GC 便会忽略这个 `map`

3. 分片解决并发竞争：bigCache 中使用了分片技术。创建 `N` 个 shard，每个 shard 包含一个带锁的 `cacheShard`，bigCache 将数据分散到不同的 `cacheShard` 进行存储。当从缓存中读写数据时，根据 `HashFunc(key)%N` 选择其中一个 `cacheShard` ，获取缓存锁 `cacheShard.lock`，这样可以大幅降低并发过程中的锁粒度。
4. [ ]byte+map\[uint64\]\[ uint64\]规避GC：从 bigCache 的 `cacheShard` 结构来看，使用了 `map[uint64]uint32` 结构，其中 key 和 value 均无指针结构，其中 value 会追加到一个全局的 `[]byte` 中，每一个 shard 中包含一个全局 `[]byte` 类型的结构 `queue.BytesQueue`。由于此字节切片除了自身对象不包含其他指针，所以 GC 对于整个 `cacheShard` 的标记时间是 `O(1)`
5. `string`, `slice`和`time.Time`都包含指针。



缺点：

1. 无持久化功能，只能用作单机缓存。
2. bigcache只能等待清理最老的元素的时候把这些"虫洞"删除掉。
3. 在添加一个元素失败后，会清理空间删除最老的元素。
4. 还会专门有一个定时的清理goroutine, 负责移除过期数据。
5. 缓存对象没有读取的时候刷新过期时间的功能，所以放入的缓存对象最终免不了过期的命运。
6. 所有的缓存对象的`lifewindow`都是一样的，比如30分钟、两小时。







参考：

https://pandaychen.github.io/2020/03/03/BIGCACHE-ANALYSIS/

https://colobu.com/2019/11/18/how-is-the-bigcache-is-fast/

https://blog.allegro.tech/2016/03/writing-fast-cache-service-in-go.html

http://liuqh.icu/2021/06/15/go/package/14-bigcache/

https://zhuanlan.zhihu.com/p/487455942



https://blog.csdn.net/xingwangc2014/article/details/86548130

https://zhuanlan.zhihu.com/p/404334020

https://www.jdon.com/52554

https://github.com/bg5sbk/go-labs



bigcache

https://mp.weixin.qq.com/s/URiURNrXHUYP1v2Q50i7Bg

https://medium.com/codex/our-go-cache-library-choices-406f2662d6b

https://blog.csdn.net/weixin_33519829/article/details/112098752

http://sarailqaq.org.cn/2020/12/06/%E8%BF%9B%E7%A8%8B%E5%86%85%E7%BC%93%E5%AD%98bigcache/



https://go.cyub.vip/concurrency/sync-rwmutex.html



好，今天我们学习一下 big 对，其他它是一个 Golang 的缓存库。然后这个缓存库它有什么优点呢？他支持存储百万的缓存条目，也非常快。然后它支持大并发访问，然后支持在一定时间后剔除条目，并且它是几乎没有 GC 的。然后我们先来看一下它是怎么用的。首先基础用法，就我们我们先把这个包引进来，然后别开始简历，然后另一个别开启另一个开始实力。然后我们需要给他传一个默认的配置参数，这配置参数有一个有一个参有一个有一个入参。这入差是它的过期时间，这个过期时间是作用于每一条，这个过去时间其实就作用于每一条条目的，它就是一个全局的这个开启它不支持配单个条目的过期时间。所以说差你这里设置了 10 分钟，它就是所有的全局的条目都是 10 分钟过期。然后创建好了过后我们就 set 一个 key value 进去，然后我们再 set 一个相同的 key 不同的 value 进去，然后我们去获取这个 key 然后得到这个条目，这个就这条目这个 value 这个值。
好，首先我们来执行一下，而执行了过后，我们可以发现给我们获取的 value 是 value 1，它并不是 value 这就说明了我们在设置 key 值，我们如果 key 相同的话，它的值会不会覆盖后有后面设置的会把前面的覆盖，而这可以理解为它哈希充足的时候它是覆盖值的。
好。然后我们第二个如果想不覆盖它怎么做呢？其中这里我们就不用 set 我们就 append 我们第一个先 set 一个 value 以及进去，然后 append value 获取了值，他就是。而这里其实他就是在追加进去的。如果说你这个相同的 K 又 append 设置进去了，就是往末尾追加，导致他的第二个 demo 第三个是我们的过去时间他是怎么搞的？如果我们在设置默认配置参数的时候，我们传一秒钟，这一秒钟就是说他所有的 K 所有的所有的条目，所有的反成条目它都是一秒钟就失效了。这个我们来试验一下。就是说我们设置 K 的设置 value 两次经过，等过了 3 秒钟我们再去获取这个 key 我们发现它是 note found 所以说这个条目就它在 1 秒过后它失效了，我们在获取的时候它就不能获取到了。
然后还有一个参数，就是可能的 window 这个要怎么理解卡他们的意思就是说我们多久去清除一次这个条目？我们多久去清除条目？这个怎么？也就是说我们在设置一条一条的条目的一个一个的缓存的时候，设置好过后这个每个缓存它都有一个过期时间，我们柯南的 window 就是多久去扫描一次这些条目的，然后并把过期的把它剔除好。
这里同样我们一个 key 一个 value 然后我们设置一个我们等 3 秒，然后再获取。它同样是 load 泛了的，因为我们这个 window 是配置了过后，它是在内部，你 6 这个被 catch 的时候，它会在 6 的时候它会启动一个 grooting 然后去定时的去执行，每间隔一秒钟他就执行轻触动作。
然后下一个 demo 是说我们的删除回调，我们删除的时候可能有些业务场景需要说我们删除这个条目的时候执行一个回调函数。好这个回调函数它是固定型号，就必须有传入一个 key 和一个 K 就是我们设置 K 这个 byte 数据就是我们设置的值。好，然后我们看下面怎么用。同样我们设置一个每一秒钟清除一次。首先我们设置一个 key 和 V 的形式，然后我们等待 3 秒，然后它就它会自动做水晶这种只是一个清楚的操作，然后执行这个回调你函数的方法。然后当我们再获取 K 的时候，他其实就是被删除了。然后最后一个是我们的也是一个删除轨道，只是说这个删除轨道它是带一个信息的，就是说这个条目是为什么被删除的。我们这个删除的里面它其实有三种状态的。第一种是过期删除，第二种是没有空间 no base no space 它就会删除。第三种是我们自己删除的。所以说它有三种删除，不懂用法方式删除。
在我们讲完了它是怎么应用，它的常用方法如何？再来了解一下它是怎么设计怎么实现这些功能的。首先我们来看一下它的基本的数，它这个设计的数结构，并看起来他其实是以叉结构，首先是 catch 里面的结构，它首先是把它这个结构分片，就是说我们看前面他可能有很多个分片，而且他是 2.0 磁场读取时候，它每一个分片里面保存了，每一个分片里面它保存了一个存储数据的和一个存储索引的 map 结构。
他是怎么实现索引数据就是说当我们的数据写进来的时候，我们通过 K 值计算一个哈希值，然后去和他的分片数量取余，求找到他的分片数的下标，然后我们去找对应的那个分片，找到那个对应的分片过后，然后我们再通通过这个 key 获取，再通过这个 key 在 map 索引结构里面获取一个偏移量，这偏移量就是我们的 banner 值在这个这个二进制数组在这个 byte 数组里面的偏移量，然后获取到这个片子，我们就可以从这个二进制从这个数字里面把我们的这个 values 取出来。其实所以说他大概就是一个这样的解决构，就是他自然结构。然后下面我们来仔细分析一下她具体的流程是什么。
首先我们看一下 set 流程，其实它就是当我们的 K 和 value 进来的时候，我们的 K 会首先计算出一个哈希 K 值，然后我们通过这哈希 K 值找到我们的分片我们是哪一个分片上我们可能找到的是第三个分片，找到三分片 3 号分片。然后找到分片过后，我们可以他要找这个分片，然后找到分片之后我们这个是个 value 值。
找到他的分片之后，我们通过这个 case 再去查找。我们通过这个 key 获取 map 里面的偏移量。获取到偏移量过后我们会检查我们这个 case 会希冲突是否在，是否在，我们这 case 不存在。然后如果存在的话我们可能会存在的话，我们会驱逐。
我们会检查是否冲突，如果冲突的话我们会自控索引数据，然后删除索引。然后并且我们会查看一下当前分片有没有可以被驱逐的数据。如果有的人就顺便把它驱逐了。然后我们会把我们的 values 包裹成一个条目。这个条目是由什么组成？是有一个八个字节的。首先它是有 8 个字节的时间戳，再加上 8 个字节的哈希，再加上两个直接的 kid 长度，再加上 kid 可以自己的 K 长度字节的 K 值和 M 字节的 value 值。
那有这个后，我们会 push 把它加入到我们的存储数据真实存储数据的半数里面。然后会再封装一次。封装的时候就把我们的会加入我们的整个上一步封装条目的长度，就是他可能是 1 到 5 字节的总长度，然后把它加在头上，然后把它写到我们的二进制数组二进制 byte 数据里面，把它写到我们的 byte 数里面。
写入了过后，我们再把这个写入的偏移量保存到 map 结构里面。好这里，然后整个写入流程就这样结束了。当然这里还有一些细节，当他写入的时候，他可能会再去做一些清除，造成如果说这里的写入的时候他的空间不足了，它其实就会去删除一部分空间，然后再移动一些骗一样，然后从头开始取。
那 get 流程 get 流程其实就是说我们通过 key 来查找他们的 value 怎么会先计算出希，然后然后找到对应的分片，再找到卖，然后通过好这好几只在卖里面找到 byte 索引，找到索引过后再从二进再从 byte 数组里面去取出这个索引对应的 value 值，然后再把它再解析这个条目里面的 value 然后最终取得的 value 这是他的 get 流程。
那我们回过头来看我们这个希这个开启，她为什么这样设计？他为什么要设计出分片？首先如果说我们这个不用开启，他如果说只有一个分片的话，它会导致一个问题，就是我们在并发读写的时候，我们如何保证数据一致？这其实你要保证数据证你就只能加锁，但加锁会降低我们的效率。
如果说我们现在有 10 个人来，他 10 个人都需要访问这个速度，那么每个人都会在这里等待，它是串行执行的一个，执行完再交给下一个。但如果说我们把这个数据分片过后，我们 10 个人可能说他要查询的 key 他是不一样的，我们可以分散到不同的分片上，每个分片上带有自己的数。比如说我们 10 个人可能他需要 10 个人查询的 key 分，通过哈希过后可以分布到三个分片上，那么他在这一秒同时执行，这一秒他就可以同时执行这三个查询。而降低了我们的冲突。我们的并发冲突它就会提升更多的效率，它就会提升效率。所以说我们可以获得更大的查询和更低的延迟。
然后还有一个就是他这里利用了一个 map 的结构 map 结构来存储具体数据的索引。为什么要这样设计？其实是因为如果我们用 map 直接存储数据的话，那么可能会因为我们这里只能存储类型的或者说这个东西它都属于是指针类型的。如果说我们存储了大量的条目过后，它就会导致我们的 GC 性，我们导致 GC 的会导致严重的 GC 耗时。我们通过这个我们通过一个时间可以看出，我们通过这个时间我们可以看出，如果说我们这个 map 结构如果存的是 string 类型或者说是指针类型，我说这个数值是我们这个 map 的值是存了 key 或 value 是存了指针类型的猫，它就会造成严重的 GC 问题，从而影响我们的查询速度，从而查询和延迟。
为什么会导致这个问题？因为我们在 GC 的时候，这个 G GC 会取我们的 map 会把我们整个 map 扫描一遍。它扫描整个 map 的时候，它每一个 map 的结构它都会拿出来，然后判断一下他是否还有引用对吧。如果说他是指针，他又会判断一下他是否还有引用，他会去把每一个元素都扫了一遍，这样就会非常耗时。
说我们的 map 结构里面存的是技术类型和 int float 布鲁布尔类型其实就在扫描的时候，他就会忽略他们，因为基础类型没有办法指向一个新的，他就会忽略他们的，然后降级我们的查询效果，降低我们的查询延时，从而提高我们的效率。这就是，别开启最。





## FreeCache

特点：

- 能存储数亿条记录（entry） 。
- 零GC开销。
- 高并发线程安全访问。
- 纯Golang代码实现。
- 支持记录（entry）过期。
- 接近LRU的替换算法。
- 严格限制内存的使用。
- 提供一个测试用的服务器，支持一些基本 Redis 命令。
- 支持迭代器。

set操作为什么高效

- 采用二分查找，极大的减少查找entry索引的时间开销。slot切片上的entry索引是根据hash16值有序排列的，对于有序集合，可以采用二分查找算法进行搜索，假设缓存了n个key，那么查找entry索引的时间复杂度为log2(n * 2^-16) = log2(n) - 16。

- 对于key不存在的情况下（找不到entry索引）。
  如果Ringbuf容量充足，则直接将entry追加到环尾，时间复杂度为O(1)。
  如果RingBuf不充足，需要将一些key移除掉，情况会复杂点，后面会单独讲解这块逻辑，不过freecache通过一定的措施，保证了移除数据的时间复杂度为O(1)，所以对于RingBuf不充足时，entry追加操作的时间复杂度也O(1)。

- 对于已经存在的key（找到entry索引）。
  如果原来给entry的value预留的容量充足的话，则直接更新原来entry的头部和value，时间复杂度为O(1)。
  如果原来给entry的value预留的容量不足的话，freecache为了避免移动底层数组数据，不直接对原来的entry进行扩容，而是将原来的entry标记为删除（懒删除），然后在环形缓冲区RingBuf的环尾追加新的entry，时间复杂度为O(1)。



key过期

- 对于过期的数据，freecache会让它继续存储在RingBuf中，RingBuf从一开始初始化之后，就固定不变了，是否删掉数据，对RingBuf的实际占用空间不会产生影响。
- 当get到一个过期缓存时，freecache会删掉缓存的entry索引（但是不会将缓存从RingBuf中移除），然后对外报ErrNotFound错误。
- 当RingBuf的容量不足时，会从环头开始遍历，如果key已经过期，这时才会将它删除掉。
- 如果一个key已经过期时，在它被freecache删除之前，如果又重新set进来（过期不会主动删除entry索引，理论上有被重新set的可能），过期的entry容量充足的情况下，则会重新复用这个entry。
- freecache这种过期机制，一方面减少了维护过期数据的工作，另一方面，freecache底层存储是采用数组来实现，要求缓存数据必须连续，缓存过期的剔除会带来空间碎片，挪动数组来维持缓存数据的连续性不是一个很好的选择。

freecache的不足

- 需要一次性申请所有缓存空间。用于实现segment的RingBuf切片，从缓存被创建之后，其容量就是固定不变的，申请的内存也会一直被占用着，空间换时间，确实避免不了。
- freecache的entry置换算法不是完全LRU，而且在某些情况下，可能会把最近经常被访问的缓存置换出去。
  entry索引切片slotsData无法一次性申请足够的容量，当slotsData容量不足时，会进行空间容量x2的扩容，这种自动扩容机制，会带来一定的性能开销。
- 由于entry过期时，不会主动清理缓存数据，这些过期缓存的entry索引还会继续保存slot切片中，这种机制会加快entry索引切片提前进行扩容，而实际上除掉这些过期缓存的entry索引，entry索引切片的容量可能还是完全充足的。
- 为了保证LRU置换能够正常进行，freecache要求entry的大小不能超过缓存大小的1/1024，而且这个限制还不给动态修改，具体可以参考github上的issues。

使用freecache的注意事项

- 缓存的数据如果可以的话，大小尽量均匀一点，可以减少RingBuf容量不足时的置换工作开销。
- 缓存的数据不易过大，这样子才能缓存更多的key，提高缓存命中率。



参考：

https://blog.csdn.net/chizhenlian/article/details/108435024

https://www.cxybb.com/article/baidu_32452525/118199343

https://juejin.cn/post/7072121084136882183



1.上线字典表替代方案

2.资产管理开发完成

3.开发资产统计
















































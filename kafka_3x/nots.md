## 我可以将事件流用于什么？

实时处理支付和金融交易，如在证券交易所，银行和保险。

实时跟踪和监控汽车、卡车、车队和装运，例如物流和汽车行业。

从物联网设备或其他设备，如工厂和风力发电厂，持续获取和分析传感器数据。

收集客户交互信息和订单并及时做出反应，例如在零售业、酒店和旅游业以及移动应用程序。

监测病人在医院的护理和预测条件的变化，以确保及时治疗的紧急情况。

连接，存储一个公司的不同部门产生的数据并使之可用。

作为数据平台、事件驱动架构和微服务的基础。



### 端到端批量压缩

在某些情况下，瓶颈实际上不是 CPU 或磁盘，而是网络带宽。 对于需要通过广域网在数据中心之间发送消息的数据管道来说尤其如此。 当然，用户总是可以一次压缩一条消息，而不需要 Kafka 的任何支持，但这会导致压缩率非常低，因为大部分冗余是由于相同类型的消息之间的重复（例如，字段名称在 Web 日志中的 JSON 或用户代理或通用字符串值）。 有效的压缩需要将多条消息一起压缩，而不是单独压缩每条消息。

Kafka 通过高效的批处理格式支持这一点。 一批消息可以聚集在一起压缩并以这种形式发送到服务器。 这批消息会以压缩的形式写入，并且会在日志中保持压缩状态，只会被消费者解压。

### 生产者

生产者直接将数据发送到作为分区领导者的代理，而无需任何中间路由层。为了帮助生产者做到这一点，所有 Kafka 节点都可以在任何给定时间回答有关哪些服务器处于活动状态以及主题分区的领导者在哪里的元数据请求，以允许生产者适当地指导其请求。

客户端控制它将消息发布到哪个分区。这可以随机完成，实现一种随机负载均衡，也可以通过一些语义划分函数来完成。我们通过允许用户指定要分区的键并使用它来散列到分区来公开语义分区的接口（如果需要，还可以选择覆盖分区函数）。例如，如果选择的键是用户 ID，那么给定用户的所有数据都将发送到同一个分区。这反过来将允许消费者对他们的消费做出地点假设。这种分区风格明确设计为允许消费者进行局部敏感处理。

### 异步发送

批处理是效率的主要驱动力之一，为了启用批处理，Kafka 生产者将尝试在内存中累积数据并在单个请求中发送更大的批处理。 批处理可以配置为累积不超过固定数量的消息，并且等待时间不超过某个固定的延迟限制（例如 64k 或 10 ms）。 这允许在服务器上累积更多要发送的字节，并减少更大的 I/O 操作。 这种缓冲是可配置的，并提供了一种机制来权衡少量额外的延迟以获得更好的吞吐量。

### 消费者

Kafka 消费者通过向引导它想要消费的分区的代理发出“获取”请求来工作。 消费者在每个请求中指定其在日志中的偏移量，并从该位置开始接收回一大块日志。 因此，消费者对这个位置有很大的控制权，并且可以在需要时将其倒回以重新使用数据。

### PUSH VS PULL

我们考虑的第一个问题是消费者是否应该从经纪人那里提取数据，或者经纪人应该将数据推送给消费者。在这方面，Kafka 遵循更传统的设计，由大多数消息传递系统共享，其中数据从生产者推送到代理，并由消费者从代理中提取。一些以日志为中心的系统，例如 Scribe 和 Apache Flume，遵循非常不同的基于推送的路径，将数据推送到下游。这两种方法各有利弊。然而，基于推送的系统难以处理不同的消费者，因为代理控制了数据传输的速率。目标通常是让消费者能够以最大可能的速率消费；不幸的是，在推送系统中，这意味着当消费者的消费率低于生产率时，消费者往往会不知所措（本质上是拒绝服务攻击）。拉式系统具有更好的特性，即消费者只是落后并在可能的情况下赶上。这可以通过某种退避协议来缓解，消费者可以通过该协议表明它已经不堪重负，但是让传输速率充分利用（但从不过度利用）消费者比看起来更棘手。以前以这种方式构建系统的尝试使我们采用了更传统的拉动模型。

基于拉取的系统的另一个优点是，它有助于对发送给消费者的数据进行积极的批处理。 基于推送的系统必须选择立即发送请求或累积更多数据，然后在不知道下游消费者是否能够立即处理它的情况下稍后发送。 如果针对低延迟进行了调整，这将导致一次发送一条消息，只是为了传输最终被缓冲，这是一种浪费。 基于拉取的设计解决了这个问题，因为消费者总是在日志中的当前位置之后拉取所有可用消息（或达到某个可配置的最大大小）。 因此，可以在不引入不必要延迟的情况下获得最佳批处理。

一个简单的基于拉的系统的缺点是，如果代理没有数据，消费者可能最终会在一个紧密的循环中轮询，实际上是忙于等待数据到达。 为了避免这种情况，我们在拉取请求中有参数，允许消费者请求在“长轮询”中阻塞，等待数据到达（并且可选地等待给定数量的字节可用以确保大传输大小）。



大多数消息传递系统保留有关在代理上消费了哪些消息的元数据。也就是说，当消息被分发给消费者时，代理要么立即在本地记录该事实，要么等待消费者的确认。这是一个相当直观的选择，实际上对于单机服务器来说，这种状态还能去哪里还不清楚。由于在许多消息传递系统中用于存储的数据结构扩展性很差，这也是一个务实的选择——因为代理知道消耗了什么，它可以立即删除它，从而保持数据大小较小。

可能不明显的是，让代理和消费者就消费的内容达成一致并不是一个微不足道的问题。如果代理在每次通过网络分发消息时立即将消息记录为已消费，那么如果消费者未能处理该消息（例如因为它崩溃或请求超时或其他原因），则该消息将丢失。为了解决这个问题，许多消息传递系统添加了确认功能，这意味着消息在发送时只标记为已发送而不是被消费；代理等待来自消费者的特定确认以将消息记录为已消费。这种策略解决了丢失消息的问题，但会产生新的问题。首先，如果消费者处理了消息但在发送确认之前失败了，那么消息将被消费两次。第二个问题是关于性能的，现在代理必须为每条消息保留多个状态（首先将其锁定，以免第二次发出，然后将其标记为永久消耗，以便可以将其删除）。必须处理棘手的问题，例如如何处理已发送但从未确认的消息。

卡夫卡以不同的方式处理这个问题。 我们的主题被划分为一组完全有序的分区，每个分区在任何给定时间由每个订阅消费者组中的一个消费者消费。 这意味着消费者在每个分区中的位置只是一个整数，即下一条要消费的消息的偏移量。 这使得关于消耗的状态非常小，每个分区只有一个数字。 这种状态可以定期检查点。 这使得消息确认的等价物非常便宜。

这个决定有一个附带好处。 消费者可以故意回退到旧的偏移量并重新使用数据。 这违反了队列的通用合同，但事实证明它是许多消费者的基本特征。 例如，如果消费者代码有错误，并且在消费了一些消息后发现，那么一旦错误被修复，消费者可以重新消费这些消息。


## 我可以将事件流用于什么？

实时处理支付和金融交易，如在证券交易所，银行和保险。

实时跟踪和监控汽车、卡车、车队和装运，例如物流和汽车行业。

从物联网设备或其他设备，如工厂和风力发电厂，持续获取和分析传感器数据。

收集客户交互信息和订单并及时做出反应，例如在零售业、酒店和旅游业以及移动应用程序。

监测病人在医院的护理和预测条件的变化，以确保及时治疗的紧急情况。

连接，存储一个公司的不同部门产生的数据并使之可用。

作为数据平台、事件驱动架构和微服务的基础。



事件被组织并长期存储在主题中。非常简单，主题类似于文件系统中的文件夹，事件是该文件夹中的文件。一个示例主题名称可以是“ payments”。Kafka 中的主题总是多个制作者和多个订阅者: 一个主题可以有零个、一个或多个向其写入事件的制作者，也可以有零个、一个或多个订阅这些事件的消费者。主题中的事件可以根据需要随时阅读ーー不同于传统的消息传递系统，事件在使用后不会被删除。相反，您可以通过每个主题的配置设置来定义 Kafka 应该将您的事件保留多长时间，之后旧的事件将被丢弃。Kafka 的性能在数据大小方面实际上是恒定的，因此长时间存储数据是完美的。

主题是分区的，这意味着主题分布在位于不同 Kafka 代理上的多个“桶”中。 数据的这种分布式放置对于可伸缩性非常重要，因为它允许客户端应用程序同时从多个代理读取和写入数据。 当一个新事件发布到一个主题时，它实际上是附加到主题的分区之一。 具有相同事件键（例如，客户或车辆 ID）的事件被写入同一个分区，并且 Kafka 保证给定主题分区的任何消费者将始终以与写入事件完全相同的顺序读取该分区的事件。

为了使您的数据具有容错性和高可用性，可以复制每个主题，甚至跨地理区域或数据中心，以便始终有多个代理拥有数据副本，以防万一出现问题，您想要 对经纪人进行维护，等等。 一个常见的生产设置是复制因子为 3，即始终存在三个数据副本。 此复制在主题分区级别执行。



```bash
bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092

bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092

bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
```

### 不要害怕文件系统！

Kafka 严重依赖文件系统来存储和缓存消息。 人们普遍认为“磁盘很慢”，这使人们怀疑持久结构能否提供具有竞争力的性能。 事实上，磁盘比人们预期的要慢得多，也快得多，这取决于它们的使用方式。 一个设计合理的磁盘结构通常可以和网络一样快。

关于磁盘性能的关键事实是，在过去十年中，硬盘驱动器的吞吐量一直不同于磁盘寻道的延迟。 因此，在具有六个 7200rpm SATA RAID-5 阵列的 JBOD 配置上线性写入的性能约为 600MB/秒，但随机写入的性能仅为约 100k/秒——相差超过 6000 倍。 这些线性读写是所有使用模式中最可预测的，并且由操作系统进行了大量优化。 现代操作系统提供预读和后写技术，以大块倍数预取数据，并将较小的逻辑写入分组为大型物理写入。 可以在此 ACM 队列文章中找到有关此问题的进一步讨论； 他们实际上发现顺序磁盘访问在某些情况下可能比随机内存访问更快！

为了弥补这种性能差异，现代操作系统越来越积极地使用主内存进行磁盘缓存。 现代操作系统很乐意将所有空闲内存转移到磁盘缓存中，而在回收内存时几乎没有性能损失。 所有的磁盘读写都会经过这个统一的缓存。 如果不使用直接 I/O，则无法轻松关闭此功能，因此即使进程维护数据的进程内缓存，此数据也可能会在 OS 页面缓存中复制，从而有效地将所有内容存储两次。

此外，我们是在 JVM 之上构建的，任何花时间研究 Java 内存使用的人都知道两件事：

- 对象的内存开销非常高，通常会使存储的数据大小翻倍（或更糟）。
- 随着堆内数据的增加，Java 垃圾收集变得越来越繁琐和缓慢。

由于这些因素，使用文件系统和依赖页面缓存优于维护内存缓存或其他结构——我们通过自动访问所有空闲内存至少使可用缓存翻倍，并且可能通过存储一个紧凑型缓存再次翻倍字节结构而不是单个对象。这样做会在 32GB 的机器上产生高达 28-30GB 的缓存，而不会受到 GC 惩罚。此外，即使服务重新启动，此缓存也会保持温暖，而进程内缓存需要在内存中重建（对于 10GB 缓存可能需要 10 分钟），否则它需要从完全冷的缓存开始（这可能意味着糟糕的初始性能）。这也大大简化了代码，因为用于维护缓存和文件系统之间一致性的所有逻辑现在都在操作系统中，这往往比一次性的进程内尝试更有效、更正确。如果您的磁盘使用倾向于线性读取，那么预读实际上是在每次磁盘读取时使用有用数据预先填充此缓存。

这表明了一种非常简单的设计：与其在内存中维护尽可能多的内容，并在空间不足时将其全部刷新到文件系统中，不如将其反转。 所有数据都会立即写入文件系统上的持久日志，而不必刷新到磁盘。 实际上这只是意味着它被转移到内核的页面缓存中。





消息系统中使用的持久数据结构通常是每个消费者队列，带有关联的 BTree 或其他通用随机访问数据结构，以维护有关消息的元数据。 BTree 是可用的最通用的数据结构，并且可以在消息传递系统中支持各种事务和非事务语义。但是，它们确实带来了相当高的成本：Btree 操作是 O(log N)。通常 O(log N) 被认为本质上等同于常数时间，但对于磁盘操作来说并非如此。磁盘搜索以 10 毫秒的速度进行，每个磁盘一次只能进行一次搜索，因此并行性受到限制。因此，即使是少量的磁盘寻道也会导致非常高的开销。由于存储系统将非常快的缓存操作与非常慢的物理磁盘操作混合在一起，因此随着数据随着固定缓存的增加而增加，树结构的观察性能通常是超线性的——即将数据加倍会使事情变得比两倍慢得多。

直观地说，持久队列可以建立在简单的读取和附加到文件上，这在日志解决方案中很常见。 这种结构的优点是所有操作都是 O(1) 并且读取不会阻塞写入或彼此。 这具有明显的性能优势，因为性能与数据大小完全分离——一台服务器现在可以充分利用许多廉价、低转速的 1+TB SATA 驱动器。 尽管它们的寻道性能很差，但这些驱动器对于大容量读取和写入具有可接受的性能，并且价格仅为其 1/3，容量为 3 倍。

在没有任何性能损失的情况下访问几乎无限的磁盘空间意味着我们可以提供一些通常在消息传递系统中没有的功能。 例如，在 Kafka 中，我们可以将消息保留相对较长的时间（比如一周），而不是尝试在消息被消费后立即删除它们。 正如我们将描述的那样，这为消费者带来了很大的灵活性。



### 效率

我们在上一节中讨论了磁盘效率。 一旦消除了不良的磁盘访问模式，这种系统效率低下的常见原因有两个：太多的小型 I/O 操作和过多的字节复制。

小的 I/O 问题既发生在客户端和服务器之间，也发生在服务器自己的持久操作中。

为了避免这种情况，我们的协议是围绕“消息集”抽象构建的，该抽象自然地将消息组合在一起。 这允许网络请求将消息组合在一起并分摊网络往返的开销，而不是一次发送单个消息。 服务器依次将消息块一次性附加到其日志中，而消费者一次获取大的线性块。

这种简单的优化会产生数量级的加速。 批处理导致更大的网络数据包、更大的顺序磁盘操作、连续的内存块等等，所有这些都允许 Kafka 将突发的随机消息写入流转换为流向消费者的线性写入。

另一个低效率是字节复制。 在低消息率下，这不是问题，但在负载下影响很大。 为了避免这种情况，我们采用了由生产者、代理和消费者共享的标准化二进制消息格式（因此数据块可以在它们之间传输而无需修改）。

代理维护的消息日志本身只是一个文件目录，每个文件都由一系列消息集填充，这些消息集以生产者和消费者使用的相同格式写入磁盘。 保持这种通用格式可以优化最重要的操作：持久日志块的网络传输。 现代 Unix 操作系统提供了一个高度优化的代码路径，用于将数据从页面缓存传输到套接字； 在 Linux 中，这是通过 sendfile 系统调用完成的。

要了解 sendfile 的影响，重要的是要了解将数据从文件传输到套接字的常用数据路径：（零拷贝）

- 操作系统从磁盘读取数据到内核空间的pagecache中
- 应用程序从内核空间读取数据到用户空间缓冲区
- 应用程序将数据写回内核空间到套接字缓冲区
- 操作系统将数据从套接字缓冲区复制到 NIC 缓冲区，然后通过网络发送

这显然是低效的，有四个副本和两个系统调用。 使用 sendfile，通过允许操作系统将数据从页面缓存直接发送到网络来避免这种重新复制。 所以在这个优化的路径中，只需要最终复制到 NIC 缓冲区。



我们期望一个常见的用例是一个主题的多个消费者。 使用上面的零复制优化，数据被复制到页面缓存中一次，并在每次消费时重复使用，而不是存储在内存中并在每次读取时复制到用户空间。 这允许以接近网络连接限制的速率消耗消息。

### 端到端批量压缩

在某些情况下，瓶颈实际上不是 CPU 或磁盘，而是网络带宽。 对于需要通过广域网在数据中心之间发送消息的数据管道来说尤其如此。 当然，用户总是可以一次压缩一条消息，而不需要 Kafka 的任何支持，但这会导致压缩率非常低，因为大部分冗余是由于相同类型的消息之间的重复（例如，字段名称在 Web 日志中的 JSON 或用户代理或通用字符串值）。 有效的压缩需要将多条消息一起压缩，而不是单独压缩每条消息。

Kafka 通过高效的批处理格式支持这一点。 一批消息可以聚集在一起压缩并以这种形式发送到服务器。 这批消息会以压缩的形式写入，并且会在日志中保持压缩状态，只会被消费者解压。

### 生产者

生产者直接将数据发送到作为分区领导者的代理，而无需任何中间路由层。为了帮助生产者做到这一点，所有 Kafka 节点都可以在任何给定时间回答有关哪些服务器处于活动状态以及主题分区的领导者在哪里的元数据请求，以允许生产者适当地指导其请求。

客户端控制它将消息发布到哪个分区。这可以随机完成，实现一种随机负载均衡，也可以通过一些语义划分函数来完成。我们通过允许用户指定要分区的键并使用它来散列到分区来公开语义分区的接口（如果需要，还可以选择覆盖分区函数）。例如，如果选择的键是用户 ID，那么给定用户的所有数据都将发送到同一个分区。这反过来将允许消费者对他们的消费做出地点假设。这种分区风格明确设计为允许消费者进行局部敏感处理。

### 异步发送

批处理是效率的主要驱动力之一，为了启用批处理，Kafka 生产者将尝试在内存中累积数据并在单个请求中发送更大的批处理。 批处理可以配置为累积不超过固定数量的消息，并且等待时间不超过某个固定的延迟限制（例如 64k 或 10 ms）。 这允许在服务器上累积更多要发送的字节，并减少更大的 I/O 操作。 这种缓冲是可配置的，并提供了一种机制来权衡少量额外的延迟以获得更好的吞吐量。

### 消费者

Kafka 消费者通过向引导它想要消费的分区的代理发出“获取”请求来工作。 消费者在每个请求中指定其在日志中的偏移量，并从该位置开始接收回一大块日志。 因此，消费者对这个位置有很大的控制权，并且可以在需要时将其倒回以重新使用数据。

### PUSH VS PULL

我们考虑的第一个问题是消费者是否应该从经纪人那里提取数据，或者经纪人应该将数据推送给消费者。在这方面，Kafka 遵循更传统的设计，由大多数消息传递系统共享，其中数据从生产者推送到代理，并由消费者从代理中提取。一些以日志为中心的系统，例如 Scribe 和 Apache Flume，遵循非常不同的基于推送的路径，将数据推送到下游。这两种方法各有利弊。然而，基于推送的系统难以处理不同的消费者，因为代理控制了数据传输的速率。目标通常是让消费者能够以最大可能的速率消费；不幸的是，在推送系统中，这意味着当消费者的消费率低于生产率时，消费者往往会不知所措（本质上是拒绝服务攻击）。拉式系统具有更好的特性，即消费者只是落后并在可能的情况下赶上。这可以通过某种退避协议来缓解，消费者可以通过该协议表明它已经不堪重负，但是让传输速率充分利用（但从不过度利用）消费者比看起来更棘手。以前以这种方式构建系统的尝试使我们采用了更传统的拉动模型。

基于拉取的系统的另一个优点是，它有助于对发送给消费者的数据进行积极的批处理。 基于推送的系统必须选择立即发送请求或累积更多数据，然后在不知道下游消费者是否能够立即处理它的情况下稍后发送。 如果针对低延迟进行了调整，这将导致一次发送一条消息，只是为了传输最终被缓冲，这是一种浪费。 基于拉取的设计解决了这个问题，因为消费者总是在日志中的当前位置之后拉取所有可用消息（或达到某个可配置的最大大小）。 因此，可以在不引入不必要延迟的情况下获得最佳批处理。

一个简单的基于拉的系统的缺点是，如果代理没有数据，消费者可能最终会在一个紧密的循环中轮询，实际上是忙于等待数据到达。 为了避免这种情况，我们在拉取请求中有参数，允许消费者请求在“长轮询”中阻塞，等待数据到达（并且可选地等待给定数量的字节可用以确保大传输大小）。



大多数消息传递系统保留有关在代理上消费了哪些消息的元数据。也就是说，当消息被分发给消费者时，代理要么立即在本地记录该事实，要么等待消费者的确认。这是一个相当直观的选择，实际上对于单机服务器来说，这种状态还能去哪里还不清楚。由于在许多消息传递系统中用于存储的数据结构扩展性很差，这也是一个务实的选择——因为代理知道消耗了什么，它可以立即删除它，从而保持数据大小较小。

可能不明显的是，让代理和消费者就消费的内容达成一致并不是一个微不足道的问题。如果代理在每次通过网络分发消息时立即将消息记录为已消费，那么如果消费者未能处理该消息（例如因为它崩溃或请求超时或其他原因），则该消息将丢失。为了解决这个问题，许多消息传递系统添加了确认功能，这意味着消息在发送时只标记为已发送而不是被消费；代理等待来自消费者的特定确认以将消息记录为已消费。这种策略解决了丢失消息的问题，但会产生新的问题。首先，如果消费者处理了消息但在发送确认之前失败了，那么消息将被消费两次。第二个问题是关于性能的，现在代理必须为每条消息保留多个状态（首先将其锁定，以免第二次发出，然后将其标记为永久消耗，以便可以将其删除）。必须处理棘手的问题，例如如何处理已发送但从未确认的消息。

卡夫卡以不同的方式处理这个问题。 我们的主题被划分为一组完全有序的分区，每个分区在任何给定时间由每个订阅消费者组中的一个消费者消费。 这意味着消费者在每个分区中的位置只是一个整数，即下一条要消费的消息的偏移量。 这使得关于消耗的状态非常小，每个分区只有一个数字。 这种状态可以定期检查点。 这使得消息确认的等价物非常便宜。

这个决定有一个附带好处。 消费者可以故意回退到旧的偏移量并重新使用数据。 这违反了队列的通用合同，但事实证明它是许多消费者的基本特征。 例如，如果消费者代码有错误，并且在消费了一些消息后发现，那么一旦错误被修复，消费者可以重新消费这些消息。

### 消息传递语义

现在我们对生产者和消费者的工作方式有了一些了解，让我们讨论一下 Kafka 在生产者和消费者之间提供的语义保证。 显然，可以提供多种可能的消息传递保证：

- 最多一次——消息可能会丢失，但永远不会重新传递。
- 至少一次——消息永远不会丢失，但可以重新传递。
- 恰好一次——这是人们真正想要的，每条消息都只传递一次。



